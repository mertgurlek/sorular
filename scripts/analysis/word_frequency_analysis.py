"""
Hibrit Kelime Frekans Analizi

VeritabanÄ±ndaki soru ve ÅŸÄ±klardan kelime frekansÄ± Ã§Ä±karÄ±r.
Ã‡ok kelimeli ifadeler (phrasal verbs, collocations, prepositional phrases)
Ã¶nce tek birim olarak tespit edilir, sonra kalan kelimeler unigram olarak sayÄ±lÄ±r.

KullanÄ±m:
    python word_frequency_analysis.py
    python word_frequency_analysis.py --category "YDS Gramer"
    python word_frequency_analysis.py --top 200
    python word_frequency_analysis.py --min-freq 5

Ã‡Ä±ktÄ±:
    word_frequency_results.json
"""

import argparse
import json
import re
import sys
import time
from collections import Counter
from datetime import datetime

from scripts.db_utils import execute_query
from scripts.english_phrases import get_phrases_by_length, get_stop_words, get_all_phrases


# ============================================================
# METÄ°N TEMÄ°ZLEME
# ============================================================

def clean_text(text: str) -> str:
    """Metni temizle: kÃ¼Ã§Ã¼k harf, gereksiz karakterleri kaldÄ±r"""
    if not text:
        return ""
    text = text.lower()
    # BoÅŸluk bÄ±rakÄ±cÄ±larÄ± (____) kaldÄ±r
    text = re.sub(r'_+', ' ', text)
    # Parantez iÃ§indeki ÅŸÄ±k harflerini kaldÄ±r: (A), (B), a), b) vb.
    text = re.sub(r'\(?[a-e]\)', '', text)
    # SayÄ±larÄ± kaldÄ±r (soru numaralarÄ± vb.)
    text = re.sub(r'\b\d+\b', '', text)
    # Noktalama iÅŸaretlerini kaldÄ±r ama apostrof koru (don't, it's)
    text = re.sub(r"[^\w\s']", ' ', text)
    # Ã‡oklu boÅŸluklarÄ± tekle
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def extract_options_text(options) -> str:
    """Options JSONB'den ÅŸÄ±k metinlerini Ã§Ä±kar"""
    if not options:
        return ""
    
    if isinstance(options, str):
        try:
            options = json.loads(options)
        except:
            return ""
    
    texts = []
    if isinstance(options, list):
        for opt in options:
            if isinstance(opt, dict):
                # {"label": "A", "text": "..."} formatÄ±
                text = opt.get("text", "") or opt.get("value", "") or ""
                texts.append(text)
            elif isinstance(opt, str):
                texts.append(opt)
    
    return " ".join(texts)


# ============================================================
# HÄ°BRÄ°T FREKANS ANALÄ°ZÄ°
# ============================================================

class HybridFrequencyAnalyzer:
    """
    Hibrit frekans analizci (sliding window â€” hÄ±zlÄ±):
    1. Metni kelime dizisine Ã§evir
    2. Uzundan kÄ±saya sliding window ile Ã§ok kelimeli ifadeleri bul
    3. EÅŸleÅŸen pozisyonlarÄ± iÅŸaretle
    4. Ä°ÅŸaretlenmemiÅŸ kelimeleri unigram olarak say
    5. Stop words filtrele
    """
    
    def __init__(self):
        self.phrases_by_length = get_phrases_by_length()
        self.stop_words = get_stop_words()
        self.all_phrases = get_all_phrases()
        
        # Uzundan kÄ±saya sÄ±ralÄ± kelime sayÄ±larÄ±
        self.sorted_lengths = sorted(self.phrases_by_length.keys(), reverse=True)
        self.max_phrase_len = self.sorted_lengths[0] if self.sorted_lengths else 1
        
        # SayaÃ§lar
        self.phrase_counter = Counter()    # Ã‡ok kelimeli ifadeler
        self.word_counter = Counter()      # Tekil kelimeler
        self.combined_counter = Counter()  # BirleÅŸik (hepsi)
        
        # Ä°statistikler
        self.total_texts = 0
        self.total_phrase_matches = 0
        self.total_word_matches = 0
    
    def analyze_text(self, text: str):
        """Tek bir metni analiz et â€” sliding window yaklaÅŸÄ±mÄ±"""
        cleaned = clean_text(text)
        if not cleaned:
            return
        
        self.total_texts += 1
        words = cleaned.split()
        n = len(words)
        used = [False] * n  # Hangi pozisyonlar Ã§ok kelimeli ifadeye ait
        
        # AdÄ±m 1: Uzundan kÄ±saya sliding window ile phrase ara
        for length in self.sorted_lengths:
            if length < 2 or length > n:
                continue
            phrases_set = self.phrases_by_length[length]
            for i in range(n - length + 1):
                if any(used[i:i + length]):
                    continue
                candidate = " ".join(words[i:i + length])
                if candidate in phrases_set:
                    self.phrase_counter[candidate] += 1
                    self.combined_counter[candidate] += 1
                    self.total_phrase_matches += 1
                    for j in range(i, i + length):
                        used[j] = True
        
        # AdÄ±m 2: KullanÄ±lmamÄ±ÅŸ kelimeleri unigram olarak say
        for i, word in enumerate(words):
            if used[i]:
                continue
            word = word.strip("'")
            if not word or len(word) < 2:
                continue
            if word in self.stop_words:
                continue
            if not word.isalpha():
                continue
            
            self.word_counter[word] += 1
            self.combined_counter[word] += 1
            self.total_word_matches += 1
    
    def get_results(self, top_n: int = 500, min_freq: int = 2) -> dict:
        """Analiz sonuÃ§larÄ±nÄ± dÃ¶ndÃ¼r"""
        
        # BirleÅŸik sÄ±ralama
        combined_top = [
            {
                "expression": expr,
                "count": count,
                "type": "phrase" if expr in self.all_phrases else "word",
                "word_count": len(expr.split())
            }
            for expr, count in self.combined_counter.most_common(top_n)
            if count >= min_freq
        ]
        
        # Sadece Ã§ok kelimeli ifadeler
        phrases_top = [
            {"expression": expr, "count": count, "word_count": len(expr.split())}
            for expr, count in self.phrase_counter.most_common(200)
            if count >= min_freq
        ]
        
        # Sadece tekil kelimeler
        words_top = [
            {"expression": expr, "count": count}
            for expr, count in self.word_counter.most_common(300)
            if count >= min_freq
        ]
        
        return {
            "combined": combined_top,
            "phrases_only": phrases_top,
            "words_only": words_top,
            "stats": {
                "total_texts_analyzed": self.total_texts,
                "total_phrase_matches": self.total_phrase_matches,
                "total_word_matches": self.total_word_matches,
                "unique_phrases_found": len(self.phrase_counter),
                "unique_words_found": len(self.word_counter),
                "unique_combined": len(self.combined_counter),
                "phrase_dictionary_size": len(self.all_phrases),
            }
        }


# ============================================================
# VERÄ°TABANI SORGULAMA
# ============================================================

def fetch_questions(category: str = None) -> list:
    """VeritabanÄ±ndan sorularÄ± Ã§ek"""
    if category:
        sql = """
            SELECT question_text, options, correct_answer, category,
                   question_tr, explanation_tr, tip
            FROM questions
            WHERE category = %s
        """
        return execute_query(sql, (category,), fetch_all=True, use_dict_cursor=True)
    else:
        sql = """
            SELECT question_text, options, correct_answer, category,
                   question_tr, explanation_tr, tip
            FROM questions
        """
        return execute_query(sql, fetch_all=True, use_dict_cursor=True)


def fetch_categories() -> list:
    """Kategorileri getir"""
    sql = """
        SELECT DISTINCT category, COUNT(*) as count
        FROM questions
        GROUP BY category
        ORDER BY count DESC
    """
    return execute_query(sql, fetch_all=True, use_dict_cursor=True)


# ============================================================
# ANA FONKSÄ°YON
# ============================================================

def run_analysis(category: str = None, top_n: int = 500, min_freq: int = 2):
    """Ana analiz fonksiyonu"""
    
    print("=" * 70)
    print("ğŸ“Š Hibrit Kelime Frekans Analizi")
    print("   Phrasal verbs + Collocations + Unigrams")
    print("=" * 70)
    
    # Kategorileri gÃ¶ster
    categories = fetch_categories()
    print(f"\nğŸ“‹ VeritabanÄ±nda {len(categories)} kategori:")
    for cat in categories:
        marker = " ğŸ‘ˆ" if category and cat['category'] == category else ""
        print(f"   - {cat['category']}: {cat['count']} soru{marker}")
    
    # SorularÄ± Ã§ek
    print(f"\nğŸ“¥ Sorular yÃ¼kleniyor...")
    start = time.time()
    questions = fetch_questions(category)
    print(f"   {len(questions)} soru yÃ¼klendi ({time.time() - start:.1f}sn)")
    
    if not questions:
        print("âŒ Soru bulunamadÄ±!")
        return
    
    # Analiz baÅŸlat
    analyzer = HybridFrequencyAnalyzer()
    
    print(f"\nğŸ” Analiz ediliyor...")
    start = time.time()
    
    for i, q in enumerate(questions):
        # Soru metnini analiz et
        analyzer.analyze_text(q.get('question_text', ''))
        
        # ÅÄ±klarÄ± analiz et
        options_text = extract_options_text(q.get('options'))
        analyzer.analyze_text(options_text)
        
        # TÃ¼rkÃ§e Ã§eviri ve aÃ§Ä±klamayÄ± ATLA (Ä°ngilizce frekans isteniyor)
        # Ama tip alanÄ± Ä°ngilizce olabilir
        tip = q.get('tip', '')
        if tip and not any(c in tip for c in 'Ã§ÅŸÄŸÃ¼Ã¶Ä±Ã‡ÅÄÃœÃ–Ä°'):
            analyzer.analyze_text(tip)
        
        if (i + 1) % 1000 == 0:
            print(f"   Ä°lerleme: {i + 1}/{len(questions)}")
    
    elapsed = time.time() - start
    print(f"   âœ… Analiz tamamlandÄ± ({elapsed:.1f}sn)")
    
    # SonuÃ§larÄ± al
    results = analyzer.get_results(top_n=top_n, min_freq=min_freq)
    
    # Konsola Ã¶zet yazdÄ±r
    print(f"\n{'=' * 70}")
    print("ğŸ“Š SONUÃ‡LAR")
    print(f"{'=' * 70}")
    
    stats = results['stats']
    print(f"\nğŸ“ˆ Ä°statistikler:")
    print(f"   Analiz edilen metin sayÄ±sÄ±: {stats['total_texts_analyzed']}")
    print(f"   Bulunan Ã§ok kelimeli ifade eÅŸleÅŸmesi: {stats['total_phrase_matches']}")
    print(f"   Bulunan tekil kelime: {stats['total_word_matches']}")
    print(f"   Benzersiz ifade: {stats['unique_phrases_found']}")
    print(f"   Benzersiz kelime: {stats['unique_words_found']}")
    print(f"   SÃ¶zlÃ¼k boyutu: {stats['phrase_dictionary_size']} ifade")
    
    # Top 50 birleÅŸik
    print(f"\nğŸ† En SÄ±k GeÃ§en 50 Ä°fade (birleÅŸik):")
    print(f"   {'#':<4} {'Ä°fade':<35} {'SayÄ±':<8} {'TÃ¼r':<10}")
    print(f"   {'-'*60}")
    for i, item in enumerate(results['combined'][:50], 1):
        type_label = "ğŸ“Œ ifade" if item['type'] == 'phrase' else "ğŸ“ kelime"
        print(f"   {i:<4} {item['expression']:<35} {item['count']:<8} {type_label}")
    
    # Top 30 Ã§ok kelimeli
    print(f"\nğŸ”— En SÄ±k GeÃ§en 30 Ã‡ok Kelimeli Ä°fade:")
    print(f"   {'#':<4} {'Ä°fade':<40} {'SayÄ±':<8}")
    print(f"   {'-'*55}")
    for i, item in enumerate(results['phrases_only'][:30], 1):
        print(f"   {i:<4} {item['expression']:<40} {item['count']:<8}")
    
    # Kategori bazlÄ± analiz
    if not category:
        print(f"\nğŸ“‚ Kategori BazlÄ± Analiz baÅŸlatÄ±lÄ±yor...")
        category_results = {}
        
        for cat in categories:
            cat_name = cat['category']
            cat_questions = [q for q in questions if q.get('category') == cat_name]
            
            cat_analyzer = HybridFrequencyAnalyzer()
            for q in cat_questions:
                cat_analyzer.analyze_text(q.get('question_text', ''))
                options_text = extract_options_text(q.get('options'))
                cat_analyzer.analyze_text(options_text)
            
            cat_results = cat_analyzer.get_results(top_n=50, min_freq=2)
            category_results[cat_name] = {
                "question_count": len(cat_questions),
                "top_expressions": cat_results['combined'][:30],
                "top_phrases": cat_results['phrases_only'][:15],
                "stats": cat_results['stats']
            }
        
        results['by_category'] = category_results
        print(f"   âœ… {len(categories)} kategori analiz edildi")
    
    # JSON'a kaydet
    output = {
        "generated_at": datetime.now().isoformat(),
        "parameters": {
            "category": category or "ALL",
            "top_n": top_n,
            "min_freq": min_freq,
            "total_questions": len(questions)
        },
        **results
    }
    
    output_file = "word_frequency_results.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ SonuÃ§lar kaydedildi: {output_file}")
    print(f"{'=' * 70}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Hibrit Kelime Frekans Analizi")
    parser.add_argument("--category", type=str, default=None, help="Belirli bir kategori filtresi")
    parser.add_argument("--top", type=int, default=500, help="En Ã§ok kaÃ§ ifade gÃ¶sterilsin (varsayÄ±lan: 500)")
    parser.add_argument("--min-freq", type=int, default=2, help="Minimum frekans eÅŸiÄŸi (varsayÄ±lan: 2)")
    
    args = parser.parse_args()
    run_analysis(category=args.category, top_n=args.top, min_freq=args.min_freq)
